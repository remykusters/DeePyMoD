{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "# DeepMoD stuff\n",
    "from deepymod import DeepMoD\n",
    "from deepymod.model.func_approx import NN\n",
    "from deepymod.model.library import Library1D\n",
    "from deepymod.model.constraint import LeastSquares\n",
    "from deepymod.model.sparse_estimators import Threshold, PDEFIND\n",
    "from deepymod.training import train\n",
    "from deepymod.training.sparsity_scheduler import TrainTestPeriodic\n",
    "from deepymod.data import Dataset\n",
    "from deepymod.data.burgers import BurgersDelta\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = 'cuda'\n",
    "#else:\n",
    "device = 'cpu'\n",
    "\n",
    "# Settings for reproducibility\n",
    "np.random.seed(44)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Making dataset\n",
    "\n",
    "noise = 0.01\n",
    "A = 1\n",
    "v = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12000, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = 1\n",
    "dataset = Dataset(BurgersDelta, A=A, v=v)\n",
    "\n",
    "x = np.linspace(-4.1, 4.1, 120) \n",
    "t = np.linspace(0.1, 1.1, 100) \n",
    "t_grid, x_grid = np.meshgrid(t, x, indexing='ij')\n",
    "X, y = dataset.create_dataset(x_grid.reshape(-1, 1), t_grid.reshape(-1, 1), n_samples=0, noise=noise, random=False, normalize=False)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = X.reshape(x_grid.shape[0],x_grid.shape[1],2)\n",
    "yt = y.reshape(x_grid.shape[0],x_grid.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1800, 1])\n",
      " 44625  MSE: 8.06e-06  Reg: 6.19e-06  L1: 1.53e+00 Algorithm converged. Writing model to disk.\n",
      "[tensor([[ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.9093],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [-0.6174],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000]], grad_fn=<MulBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "for n_x in np.array([18]):\n",
    "    number_of_samples = n_x\n",
    "    ytrain = np.empty([yt.shape[0],number_of_samples])\n",
    "    xtrain = np.empty([xt.shape[0],number_of_samples,xt.shape[2]])\n",
    "    for i in np.arange(yt.shape[0]):\n",
    "        idx = np.random.permutation(yt.shape[1])\n",
    "        ytrain[i,:] = yt[i,idx][:number_of_samples]\n",
    "        xtrain[i,:,0] = xt[i,idx,0][:number_of_samples]\n",
    "        xtrain[i,:,1] = xt[i,idx,1][:number_of_samples]\n",
    "    xtrain_b = np.transpose(xtrain,axes=(1,0,2))\n",
    "    ytrain_b = ytrain.T\n",
    "    X = torch.tensor(xtrain_b.reshape(-1,2), dtype=torch.float32, requires_grad=True)\n",
    "    y = torch.tensor(ytrain_b.reshape(-1,1), dtype=torch.float32)\n",
    "    print(y.shape)\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    network = NN(2, [30, 30, 30, 30], 1)\n",
    "    library = Library1D(poly_order=2, diff_order=3) # Library function\n",
    "    estimator = Threshold(0.2) # Sparse estimator \n",
    "    constraint = LeastSquares() # How to constrain\n",
    "    model = DeepMoD(network, library, estimator, constraint).to(device) # Putting it all in the model\n",
    "\n",
    "    sparsity_scheduler = TrainTestPeriodic(periodicity=50, patience=500, delta=1e-7) # in terms of write iterations\n",
    "    optimizer = torch.optim.Adam(model.parameters(), betas=(0.99, 0.99), amsgrad=True, lr=1e-3) # Defining optimizer\n",
    "\n",
    "    train(model, X, y, optimizer, sparsity_scheduler, log_dir='runs/random_grid'+str(n_x), split=0.8, write_iterations=25, max_iterations=100000, delta=1e-4, patience=500) \n",
    "    print(model.constraint_coeffs(sparse=True, scaled=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28500  MSE: 8.57e-06  Reg: 4.27e-06  L1: 1.41e+00 Algorithm converged. Writing model to disk.\n",
      "[tensor([[ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.6382],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [-0.7670],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000]], device='cuda:0', grad_fn=<MulBackward0>)]\n",
      " 99975  MSE: 6.56e-06  Reg: 9.61e-07  L1: 3.85e+00 Algorithm converged. Writing model to disk.\n",
      "[tensor([[ 7.9732e-04],\n",
      "        [-3.5464e-02],\n",
      "        [ 6.7906e-01],\n",
      "        [ 6.0199e-02],\n",
      "        [ 2.7272e-01],\n",
      "        [-8.8315e-01],\n",
      "        [-3.8879e-01],\n",
      "        [-2.4706e-01],\n",
      "        [-4.5990e-01],\n",
      "        [ 2.9216e-01],\n",
      "        [ 2.1149e-01],\n",
      "        [ 3.2241e-01]], device='cuda:0', grad_fn=<MulBackward0>)]\n",
      " 36300  MSE: 1.05e-05  Reg: 4.87e-06  L1: 1.46e+00 "
     ]
    }
   ],
   "source": [
    "for n_x in np.array([4,6,8,10,12,14,16]):\n",
    "    for run in np.arange(runs):\n",
    "        \n",
    "        number_of_samples = n_x * 100\n",
    "        idx = np.random.permutation(y.shape[0])\n",
    "        X = torch.tensor(X[idx, :][:number_of_samples], dtype=torch.float32, requires_grad=True)\n",
    "        y = torch.tensor(y[idx, :][:number_of_samples], dtype=torch.float32)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        network = NN(2, [30, 30, 30, 30], 1)\n",
    "        library = Library1D(poly_order=2, diff_order=3) # Library function\n",
    "        estimator = Threshold(0.2) # Sparse estimator \n",
    "        constraint = LeastSquares() # How to constrain\n",
    "        model = DeepMoD(network, library, estimator, constraint).to(device) # Putting it all in the model\n",
    "\n",
    "        sparsity_scheduler = TrainTestPeriodic(periodicity=50, patience=500, delta=1e-7) # in terms of write iterations\n",
    "        optimizer = torch.optim.Adam(model.parameters(), betas=(0.99, 0.99), amsgrad=True, lr=1e-3) # Defining optimizer\n",
    "\n",
    "        train(model, X, y, optimizer, sparsity_scheduler, log_dir='runs/rand'+str(n_x), split=0.8, write_iterations=25, max_iterations=100000, delta=1e-4, patience=500) \n",
    "        print(model.constraint_coeffs(sparse=True, scaled=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
