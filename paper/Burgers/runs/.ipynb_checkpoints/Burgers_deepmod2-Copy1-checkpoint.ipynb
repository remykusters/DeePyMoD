{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "# DeepMoD stuff\n",
    "from deepymod import DeepMoD\n",
    "from deepymod.model.func_approx import NN\n",
    "from deepymod.model.library import Library1D\n",
    "from deepymod.model.constraint import LeastSquares\n",
    "from deepymod.model.sparse_estimators import Threshold, PDEFIND\n",
    "from deepymod.training import train\n",
    "from deepymod.training.sparsity_scheduler import TrainTestPeriodic\n",
    "from deepymod.data import Dataset\n",
    "from deepymod.data.burgers import BurgersDelta\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "# Settings for reproducibility\n",
    "np.random.seed(44)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Making dataset\n",
    "\n",
    "noise = 0.02\n",
    "A = 1\n",
    "v = 0.25\n",
    "\n",
    "runs = 1\n",
    "dataset = Dataset(BurgersDelta, A=A, v=v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 76125  MSE: 2.49e-05  Reg: 4.11e-06  L1: 1.53e+00 "
     ]
    }
   ],
   "source": [
    "x = (np.random.rand(1,15)-0.5)*4\n",
    "t = np.linspace(0.1, 1.1, 100) \n",
    "t_grid, x_grid = np.meshgrid(t, x, indexing='ij')\n",
    "X, y = dataset.create_dataset(x_grid.reshape(-1, 1), t_grid.reshape(-1, 1), n_samples=0, noise=noise, random=True, normalize=False)\n",
    "X, y = X.to(device), y.to(device)\n",
    "network = NN(2, [30, 30, 30, 30], 1)\n",
    "library = Library1D(poly_order=2, diff_order=3) # Library function\n",
    "estimator = Threshold(0.1) # Sparse estimator \n",
    "constraint = LeastSquares() # How to constrain\n",
    "model = DeepMoD(network, library, estimator, constraint).to(device) # Putting it all in the model\n",
    "\n",
    "sparsity_scheduler = TrainTestPeriodic(periodicity=50, patience=200, delta=1e-5) # in terms of write iterations\n",
    "optimizer = torch.optim.Adam(model.parameters(), betas=(0.99, 0.99), amsgrad=True, lr=1e-3) # Defining optimizer\n",
    "\n",
    "train(model, X, y, optimizer, sparsity_scheduler, log_dir='runs/figure_4', split=0.8, write_iterations=25, max_iterations=100000, delta=1e-5, patience=200) \n",
    "print(model.constraint_coeffs(sparse=True, scaled=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99975  MSE: 3.25e-05  Reg: 7.04e-06  L1: 1.35e+00 Algorithm converged. Writing model to disk.\n",
      "[tensor([[ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.7474],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [-0.5980],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000]], device='cuda:0', grad_fn=<MulBackward0>)]\n",
      " 70525  MSE: 2.35e-04  Reg: 1.48e-05  L1: 2.71e+00 Algorithm converged. Writing model to disk.\n",
      "[tensor([[ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.6818],\n",
      "        [-0.4993],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [-1.5243],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000]], device='cuda:0', grad_fn=<MulBackward0>)]\n",
      " 81250  MSE: 1.87e-05  Reg: 1.16e-06  L1: 1.63e+00 Algorithm converged. Writing model to disk.\n",
      "[tensor([[ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.8893],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [-0.7388],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000]], device='cuda:0', grad_fn=<MulBackward0>)]\n",
      " 49025  MSE: 3.42e-05  Reg: 4.28e-06  L1: 1.68e+00 Algorithm converged. Writing model to disk.\n",
      "[tensor([[ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 1.0153],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [-0.6656],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000]], device='cuda:0', grad_fn=<MulBackward0>)]\n",
      " 79950  MSE: 4.15e-05  Reg: 7.22e-06  L1: 1.45e+00 Algorithm converged. Writing model to disk.\n",
      "[tensor([[ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.8969],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [-0.5544],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000]], device='cuda:0', grad_fn=<MulBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "#for n_x in np.array([4,6,8,10,12,14,16]):\n",
    "for n_x in np.array([10,12,14,16,20]):\n",
    "    for run in np.arange(runs):\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number_of_samples = 1000\n",
    "\n",
    "#idx = np.random.permutation(y.shape[0])\n",
    "#X = torch.tensor(X[idx, :][:number_of_samples], dtype=torch.float32, requires_grad=True)\n",
    "#y = torch.tensor(y[idx, :][:number_of_samples], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = X.to(device), y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18775  MSE: 5.72e-05  Reg: 9.18e-06  L1: 2.44e+00 "
     ]
    }
   ],
   "source": [
    "for run in np.arange(runs):\n",
    "    network = NN(2, [30, 30, 30, 30], 1)\n",
    "    library = Library1D(poly_order=2, diff_order=3) # Library function\n",
    "    estimator = Threshold(0.2) # Sparse estimator \n",
    "    constraint = LeastSquares() # How to constrain\n",
    "    model = DeepMoD(network, library, estimator, constraint).to(device) # Putting it all in the model\n",
    "\n",
    "    sparsity_scheduler = TrainTestPeriodic(periodicity=50, patience=500, delta=1e-7) # in terms of write iterations\n",
    "    optimizer = torch.optim.Adam(model.parameters(), betas=(0.99, 0.99), amsgrad=True, lr=1e-3) # Defining optimizer\n",
    "\n",
    "    train(model, X, y, optimizer, sparsity_scheduler, log_dir='runs/x_rand_b_1000', split=0.8, write_iterations=25, max_iterations=100000, delta=1e-4, patience=500) \n",
    "    print(model.constraint_coeffs(sparse=True, scaled=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
