{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "# DeepMoD stuff\n",
    "from deepymod import DeepMoD\n",
    "from deepymod.model.func_approx import NN\n",
    "from deepymod.model.library import Library1D\n",
    "from deepymod.model.constraint import LeastSquares\n",
    "from deepymod.model.sparse_estimators import Threshold, PDEFIND\n",
    "from deepymod.training import train\n",
    "from deepymod.training.sparsity_scheduler import TrainTestPeriodic\n",
    "from deepymod.data import Dataset\n",
    "from deepymod.data.burgers import BurgersDelta\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = 'cuda'\n",
    "\n",
    "#else:\n",
    "device = 'cpu'\n",
    "\n",
    "# Settings for reproducibility\n",
    "np.random.seed(44)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Making dataset\n",
    "\n",
    "noise = 0.2\n",
    "A = 1\n",
    "v = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = 1\n",
    "dataset = Dataset(BurgersDelta, A=A, v=v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99975  MSE: 1.84e-04  Reg: 3.39e-08  L1: 2.16e+00 Algorithm converged. Writing model to disk.\n",
      "[tensor([[ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.7506],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [-1.4080],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000]], grad_fn=<MulBackward0>)]\n",
      " 14050  MSE: 1.15e-03  Reg: 6.42e-06  L1: 2.07e+00 Algorithm converged. Writing model to disk.\n",
      "[tensor([[ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.9112],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [-0.6642],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [-0.4917],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000]], grad_fn=<MulBackward0>)]\n",
      " 99975  MSE: 1.70e-03  Reg: 6.75e-07  L1: 4.36e+00 Algorithm converged. Writing model to disk.\n",
      "[tensor([[ 0.0000],\n",
      "        [-1.3806],\n",
      "        [ 0.7080],\n",
      "        [ 0.6758],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 1.5970],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000]], grad_fn=<MulBackward0>)]\n",
      " 58100  MSE: 1.95e-03  Reg: 4.70e-06  L1: 1.76e+01 Algorithm converged. Writing model to disk.\n",
      "[tensor([[ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 1.0542],\n",
      "        [-3.5003],\n",
      "        [ 1.3674],\n",
      "        [-0.8564],\n",
      "        [ 0.9355],\n",
      "        [ 0.0000],\n",
      "        [-2.7784],\n",
      "        [-1.6089],\n",
      "        [-5.3379],\n",
      "        [ 0.1725]], grad_fn=<MulBackward0>)]\n",
      " 99975  MSE: 2.16e-03  Reg: 4.55e-06  L1: 1.08e+01 Algorithm converged. Writing model to disk.\n",
      "[tensor([[ 0.0000],\n",
      "        [-0.2797],\n",
      "        [ 1.3576],\n",
      "        [ 1.0943],\n",
      "        [ 1.2134],\n",
      "        [-0.7544],\n",
      "        [-0.8434],\n",
      "        [-0.8448],\n",
      "        [-3.5750],\n",
      "        [-0.8191],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000]], grad_fn=<MulBackward0>)]\n",
      " 99975  MSE: 2.17e-03  Reg: 2.69e-06  L1: 1.62e+01 Algorithm converged. Writing model to disk.\n",
      "[tensor([[ 0.0000],\n",
      "        [-1.2067],\n",
      "        [ 2.0262],\n",
      "        [ 1.3487],\n",
      "        [ 0.6309],\n",
      "        [ 2.7202],\n",
      "        [-0.4272],\n",
      "        [ 1.4280],\n",
      "        [-3.3107],\n",
      "        [ 1.3175],\n",
      "        [-1.7456],\n",
      "        [ 0.0000]], grad_fn=<MulBackward0>)]\n",
      " 80750  MSE: 2.21e-03  Reg: 3.65e-06  L1: 2.94e+00 Algorithm converged. Writing model to disk.\n",
      "[tensor([[ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.9952],\n",
      "        [ 0.0000],\n",
      "        [ 0.2848],\n",
      "        [ 0.0000],\n",
      "        [-0.5038],\n",
      "        [ 0.0000],\n",
      "        [-1.1542],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000]], grad_fn=<MulBackward0>)]\n",
      " 82550  MSE: 2.22e-03  Reg: 6.77e-06  L1: 3.83e+00 "
     ]
    }
   ],
   "source": [
    "#for n_x in np.array([4,6,8,10,12,14,16,20,25,30]):\n",
    "for n_x in np.array([18,22,35]):\n",
    "    for run in np.arange(runs):\n",
    "        \n",
    "        x = np.linspace(-4, 4, n_x) \n",
    "        t = np.linspace(0.1, 1.1, 100) \n",
    "        t_grid, x_grid = np.meshgrid(t, x, indexing='ij')\n",
    "        X, y = dataset.create_dataset(x_grid.reshape(-1, 1), t_grid.reshape(-1, 1), n_samples=0, noise=noise, random=True, normalize=False)\n",
    "        \n",
    "        X, y = X.to(device), y.to(device)\n",
    "        network = NN(2, [30, 30, 30, 30], 1)\n",
    "        library = Library1D(poly_order=2, diff_order=3) # Library function\n",
    "        estimator = Threshold(0.2) # Sparse estimator \n",
    "        constraint = LeastSquares() # How to constrain\n",
    "        model = DeepMoD(network, library, estimator, constraint).to(device) # Putting it all in the model\n",
    "\n",
    "        sparsity_scheduler = TrainTestPeriodic(periodicity=50, patience=500, delta=1e-7) # in terms of write iterations\n",
    "        optimizer = torch.optim.Adam(model.parameters(), betas=(0.99, 0.99), amsgrad=True, lr=1e-3) # Defining optimizer\n",
    "\n",
    "        train(model, X, y, optimizer, sparsity_scheduler, log_dir='runs/normal_grid_noise_20/normal_grid'+str(n_x), split=0.8, write_iterations=25, max_iterations=100000, delta=1e-4, patience=500) \n",
    "        print(model.constraint_coeffs(sparse=True, scaled=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "# DeepMoD stuff\n",
    "from deepymod import DeepMoD\n",
    "from deepymod.model.func_approx import NN\n",
    "from deepymod.model.library import Library1D\n",
    "from deepymod.model.constraint import LeastSquares\n",
    "from deepymod.model.sparse_estimators import Threshold, PDEFIND\n",
    "from deepymod.training import train\n",
    "from deepymod.training.sparsity_scheduler import TrainTestPeriodic\n",
    "from deepymod.data import Dataset\n",
    "from deepymod.data.burgers import BurgersDelta\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = 'cuda'\n",
    "\n",
    "#else:\n",
    "device = 'cpu'\n",
    "\n",
    "# Settings for reproducibility\n",
    "np.random.seed(44)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Making dataset\n",
    "\n",
    "noise = 0.01\n",
    "A = 1\n",
    "v = 0.25\n",
    "\n",
    "runs = 1\n",
    "dataset = Dataset(BurgersDelta, A=A, v=v)\n",
    "\n",
    "for n_x in np.array([16,18,22,35,20,25,30]):\n",
    "#for n_x in np.array([2]):\n",
    "    for run in np.arange(runs):\n",
    "        \n",
    "        x = np.linspace(-4, 4, n_x) \n",
    "        t = np.linspace(0.1, 1.1, 100) \n",
    "        t_grid, x_grid = np.meshgrid(t, x, indexing='ij')\n",
    "        X, y = dataset.create_dataset(x_grid.reshape(-1, 1), t_grid.reshape(-1, 1), n_samples=0, noise=noise, random=True, normalize=False)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        network = NN(2, [30, 30, 30, 30], 1)\n",
    "        library = Library1D(poly_order=2, diff_order=3) # Library function\n",
    "        estimator = Threshold(0.2) # Sparse estimator \n",
    "        constraint = LeastSquares() # How to constrain\n",
    "        model = DeepMoD(network, library, estimator, constraint).to(device) # Putting it all in the model\n",
    "\n",
    "        sparsity_scheduler = TrainTestPeriodic(periodicity=50, patience=500, delta=1e-7) # in terms of write iterations\n",
    "        optimizer = torch.optim.Adam(model.parameters(), betas=(0.99, 0.99), amsgrad=True, lr=1e-3) # Defining optimizer\n",
    "\n",
    "        train(model, X, y, optimizer, sparsity_scheduler, log_dir='runs/normal_grid/normal_grid'+str(n_x), split=0.8, write_iterations=25, max_iterations=100000, delta=1e-4, patience=500) \n",
    "        print(model.constraint_coeffs(sparse=True, scaled=True))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
