{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Advection-Diffusion equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this notebook we provide a simple example of the DeepMoD algorithm and apply it on the 2D advection-diffusion equation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import torch\n",
    "# DeepMoD functions\n",
    "from deepymod import DeepMoD\n",
    "from deepymod.model.func_approx import NN\n",
    "from deepymod.model.library import Library2D_third\n",
    "from deepymod.model.constraint import LeastSquares\n",
    "from deepymod.model.sparse_estimators import Threshold,PDEFIND\n",
    "from deepymod.training import train\n",
    "from deepymod.training.sparsity_scheduler import TrainTestPeriodic\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Settings for reproducibility\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we prepare the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat('../Diffusion_2D_space81.mat')\n",
    "data = np.real(data['Expression1']).reshape((81,81,81,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 81, 81, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "datax = data[:,:,:,1]\n",
    "datay = data[:,:,:,2]\n",
    "datat = data[:,:,:,0]\n",
    "datau = data[:,:,:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 81)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datau[:,:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = 10\n",
    "tot_samples = number_of_samples*number_of_samples\n",
    "Utrain = np.empty([tot_samples,data.shape[2]])\n",
    "Xtrain = np.empty([tot_samples,data.shape[2],3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 81)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Utrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(datax.shape[2]):\n",
    "    idx = np.random.permutation(number_of_samples)\n",
    "    idy = np.random.permutation(number_of_samples)\n",
    "    Utrain[:,i] = np.array([datau[idx,k,i] for k in idy]).flatten()\n",
    "    Xtrain[:,i,1] = np.array([datax[idx,k,i] for k in idy]).flatten()\n",
    "    Xtrain[:,i,2] = np.array([datay[idx,k,i] for k in idy]).flatten()\n",
    "    Xtrain[:,i,0] = np.array([datat[idx,k,i] for k in idy]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 81)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Utrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Utrain.flatten()\n",
    "X = Xtrain.reshape(-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Add noise \n",
    "noise_level = 0.0\n",
    "y_noisy = y + noise_level * np.std(y) * np.random.randn(y.size, 1)\n",
    "\n",
    "# Randomize data \n",
    "\n",
    "idx = np.random.permutation(y.shape[0])\n",
    "X_train = torch.tensor(X[idx, :], dtype=torch.float32, requires_grad=True).to(device)\n",
    "y_train = torch.tensor(y_noisy[idx, :], dtype=torch.float32).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27550  MSE: 2.45e-02  Reg: 4.36e-10  L1: 2.32e+00 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-5d0ecb030bad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mlogdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'runs/test/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msparsity_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Github/DeePyMoD_sensor/src/deepymod/training/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data, target, optimizer, sparsity_scheduler, split, exp_ID, log_dir, max_iterations, write_iterations, **convergence_kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# Optimizer step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Configure DeepMoD\n",
    "\n",
    "network = NN(3, [40, 40, 40, 40], 1)\n",
    "library = Library2D_third(poly_order=0) \n",
    "estimator = Threshold(0.05) \n",
    "sparsity_scheduler = TrainTestPeriodic(periodicity=50, patience=200, delta=1e-5) \n",
    "constraint = LeastSquares() \n",
    "model = DeepMoD(network, library, estimator, constraint).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), betas=(0.99, 0.99), amsgrad=True, lr=2e-3) \n",
    "logdir='runs/test/'\n",
    "train(model, X_train, y_train, optimizer,sparsity_scheduler, log_dir=logdir, split=0.8, max_iterations=50000, delta=1e-6, patience=200) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dowmsampled shape: (17, 17, 41) Total number of data points: 11849\n",
      " 49975  MSE: 8.70e-06  Reg: 8.07e-06  L1: 1.64e+00 Algorithm converged. Writing model to disk.\n",
      "Dowmsampled shape: (17, 17, 21) Total number of data points: 6069\n",
      " 49975  MSE: 4.26e-06  Reg: 5.59e-06  L1: 1.43e+00 Algorithm converged. Writing model to disk.\n",
      "Dowmsampled shape: (17, 17, 11) Total number of data points: 3179\n",
      " 49975  MSE: 2.80e-06  Reg: 3.69e-06  L1: 1.47e+00 Algorithm converged. Writing model to disk.\n",
      "Dowmsampled shape: (17, 17, 7) Total number of data points: 2023\n",
      " 49975  MSE: 3.36e-06  Reg: 2.87e-06  L1: 1.41e+00 Algorithm converged. Writing model to disk.\n",
      "Dowmsampled shape: (17, 17, 6) Total number of data points: 1734\n",
      "  4700  MSE: 2.09e-04  Reg: 7.78e-06  L1: 1.00e+00 Algorithm converged. Writing model to disk.\n",
      "Dowmsampled shape: (17, 17, 5) Total number of data points: 1445\n",
      " 49975  MSE: 4.50e-05  Reg: 1.17e-05  L1: 1.71e+00 Algorithm converged. Writing model to disk.\n",
      "Dowmsampled shape: (17, 17, 4) Total number of data points: 1156\n",
      " 49975  MSE: 2.98e-05  Reg: 8.04e-06  L1: 1.42e+00 Algorithm converged. Writing model to disk.\n",
      "Dowmsampled shape: (17, 17, 3) Total number of data points: 867\n",
      " 49975  MSE: 5.90e-06  Reg: 2.42e-06  L1: 1.26e+00 Algorithm converged. Writing model to disk.\n"
     ]
    }
   ],
   "source": [
    "for i in time_range:\n",
    "    \n",
    "    # Downsample data and prepare data without noise:\n",
    "    down_data= np.take(np.take(np.take(data,np.arange(0,x_dim,5),axis=0),np.arange(0,y_dim,5),axis=1),np.arange(0,t_dim,i),axis=2)\n",
    "    print(\"Dowmsampled shape:\",down_data.shape, \"Total number of data points:\", np.product(down_data.shape))\n",
    "    index = len(np.arange(0,t_dim,i))    \n",
    "    width, width_2, steps = down_data.shape\n",
    "    x_arr, y_arr, t_arr = np.linspace(0,1,width), np.linspace(0,1,width_2), np.linspace(0,1,steps)\n",
    "    x_grid, y_grid, t_grid = np.meshgrid(x_arr, y_arr, t_arr, indexing='ij')\n",
    "    X, y = np.transpose((t_grid.flatten(), x_grid.flatten(), y_grid.flatten())), np.float32(down_data.reshape((down_data.size, 1)))\n",
    "    \n",
    "    \n",
    "    # Add noise \n",
    "    noise_level = 0.0\n",
    "    y_noisy = y + noise_level * np.std(y) * np.random.randn(y.size, 1)\n",
    "\n",
    "    # Randomize data \n",
    "\n",
    "    idx = np.random.permutation(y.shape[0])\n",
    "    X_train = torch.tensor(X[idx, :], dtype=torch.float32, requires_grad=True).to(device)\n",
    "    y_train = torch.tensor(y_noisy[idx, :], dtype=torch.float32).to(device)\n",
    "\n",
    "    # Configure DeepMoD\n",
    "\n",
    "    network = NN(3, [40, 40, 40, 40], 1)\n",
    "    library = Library2D_third(poly_order=0) \n",
    "    estimator = Threshold(0.05) \n",
    "    sparsity_scheduler = TrainTestPeriodic(periodicity=50, patience=200, delta=1e-5) \n",
    "    constraint = LeastSquares() \n",
    "    model = DeepMoD(network, library, estimator, constraint).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), betas=(0.99, 0.99), amsgrad=True, lr=2e-3) \n",
    "    logdir='final_runs/no_noise_x17/'+str(index)+'/'\n",
    "    train(model, X_train, y_train, optimizer,sparsity_scheduler, log_dir=logdir, split=0.8, max_iterations=50000, delta=1e-6, patience=200) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
